{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulk98/Transfer-learning/blob/master/Image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QCgRdPHZ0ocR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9c27ee48-1171-4c43-dec1-72d2b14bcc61"
      },
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "%cd data\n",
        "!wget \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-28 11:18:44--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 23.218.108.168, 2600:1409:0:484::e59, 2600:1409:0:495::e59\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|23.218.108.168|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824894548 (787M) [application/octet-stream]\n",
            "Saving to: ‘kagglecatsanddogs_3367a.zip’\n",
            "\n",
            "kagglecatsanddogs_3 100%[===================>] 786.68M  84.3MB/s    in 9.8s    \n",
            "\n",
            "2019-02-28 11:18:54 (79.9 MB/s) - ‘kagglecatsanddogs_3367a.zip’ saved [824894548/824894548]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-y1Egwvs1Cxm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip kagglecatsanddogs_3367a.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VQp_VaCZ1Uhb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "728a875e-7cbc-4922-eff7-4b55eaab1605"
      },
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GYSP1fgh1WPk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb486714-0d8d-48d6-eb9f-3c8e75300cef"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.applications import MobileNet\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "MRvBT8N-1Zyo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ae9809c2-33bd-4b50-9572-8ab33c65f738"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "base_model=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
        "x=Dense(512,activation='relu')(x) #dense layer 3\n",
        "preds=Dense(2,activation='softmax')(x) #final layer with softmax activation"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:208: UserWarning: MobileNet shape is undefined. Weights for input shape (224, 224) will be loaded.\n",
            "  warnings.warn('MobileNet shape is undefined.'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "w1qcLu0g1wCo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=Model(inputs=base_model.input,outputs=preds)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FqHgYCtS16QO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1581
        },
        "outputId": "a05d03af-f4b2-4a7f-86c0-9d14a16bb1b5"
      },
      "cell_type": "code",
      "source": [
        "for i,layer in enumerate(model.layers):\n",
        "  print(i,layer.name)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_1\n",
            "1 conv1_pad\n",
            "2 conv1\n",
            "3 conv1_bn\n",
            "4 conv1_relu\n",
            "5 conv_dw_1\n",
            "6 conv_dw_1_bn\n",
            "7 conv_dw_1_relu\n",
            "8 conv_pw_1\n",
            "9 conv_pw_1_bn\n",
            "10 conv_pw_1_relu\n",
            "11 conv_pad_2\n",
            "12 conv_dw_2\n",
            "13 conv_dw_2_bn\n",
            "14 conv_dw_2_relu\n",
            "15 conv_pw_2\n",
            "16 conv_pw_2_bn\n",
            "17 conv_pw_2_relu\n",
            "18 conv_dw_3\n",
            "19 conv_dw_3_bn\n",
            "20 conv_dw_3_relu\n",
            "21 conv_pw_3\n",
            "22 conv_pw_3_bn\n",
            "23 conv_pw_3_relu\n",
            "24 conv_pad_4\n",
            "25 conv_dw_4\n",
            "26 conv_dw_4_bn\n",
            "27 conv_dw_4_relu\n",
            "28 conv_pw_4\n",
            "29 conv_pw_4_bn\n",
            "30 conv_pw_4_relu\n",
            "31 conv_dw_5\n",
            "32 conv_dw_5_bn\n",
            "33 conv_dw_5_relu\n",
            "34 conv_pw_5\n",
            "35 conv_pw_5_bn\n",
            "36 conv_pw_5_relu\n",
            "37 conv_pad_6\n",
            "38 conv_dw_6\n",
            "39 conv_dw_6_bn\n",
            "40 conv_dw_6_relu\n",
            "41 conv_pw_6\n",
            "42 conv_pw_6_bn\n",
            "43 conv_pw_6_relu\n",
            "44 conv_dw_7\n",
            "45 conv_dw_7_bn\n",
            "46 conv_dw_7_relu\n",
            "47 conv_pw_7\n",
            "48 conv_pw_7_bn\n",
            "49 conv_pw_7_relu\n",
            "50 conv_dw_8\n",
            "51 conv_dw_8_bn\n",
            "52 conv_dw_8_relu\n",
            "53 conv_pw_8\n",
            "54 conv_pw_8_bn\n",
            "55 conv_pw_8_relu\n",
            "56 conv_dw_9\n",
            "57 conv_dw_9_bn\n",
            "58 conv_dw_9_relu\n",
            "59 conv_pw_9\n",
            "60 conv_pw_9_bn\n",
            "61 conv_pw_9_relu\n",
            "62 conv_dw_10\n",
            "63 conv_dw_10_bn\n",
            "64 conv_dw_10_relu\n",
            "65 conv_pw_10\n",
            "66 conv_pw_10_bn\n",
            "67 conv_pw_10_relu\n",
            "68 conv_dw_11\n",
            "69 conv_dw_11_bn\n",
            "70 conv_dw_11_relu\n",
            "71 conv_pw_11\n",
            "72 conv_pw_11_bn\n",
            "73 conv_pw_11_relu\n",
            "74 conv_pad_12\n",
            "75 conv_dw_12\n",
            "76 conv_dw_12_bn\n",
            "77 conv_dw_12_relu\n",
            "78 conv_pw_12\n",
            "79 conv_pw_12_bn\n",
            "80 conv_pw_12_relu\n",
            "81 conv_dw_13\n",
            "82 conv_dw_13_bn\n",
            "83 conv_dw_13_relu\n",
            "84 conv_pw_13\n",
            "85 conv_pw_13_bn\n",
            "86 conv_pw_13_relu\n",
            "87 global_average_pooling2d_1\n",
            "88 dense_1\n",
            "89 dense_2\n",
            "90 dense_3\n",
            "91 dense_4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3vjvqCn_18zB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    layer.trainable=False\n",
        "# or if we want to set the first 20 layers of the network to be non-trainable\n",
        "for layer in model.layers[:20]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[20:]:\n",
        "    layer.trainable=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F4iaMAib2EJO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b56cfb1e-a7d3-48b5-ce5c-fc622dd561a7"
      },
      "cell_type": "code",
      "source": [
        "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory('data/PetImages',\n",
        "                                                 target_size=(224,224),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=128,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qoP8PiXV2POC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ad5abd8e-c9ea-493e-9560-f55af31e16ca"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "# Adam optimizer\n",
        "# loss function will be categorical cross entropy\n",
        "# evaluation metric will be accuracy\n",
        "\n",
        "step_size_train=train_generator.n//train_generator.batch_size\n",
        "model.fit_generator(generator=train_generator,\n",
        "                   steps_per_epoch=step_size_train,\n",
        "                   epochs=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/1\n",
            "  1/195 [..............................] - ETA: 2:33:29 - loss: 0.6871 - acc: 0.5156"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}